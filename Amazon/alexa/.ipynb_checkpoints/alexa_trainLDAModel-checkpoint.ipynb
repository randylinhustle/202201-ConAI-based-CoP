{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01491ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import re, numpy as np, pandas as pd\n",
    "import tqdm\n",
    "import glob\n",
    "from cleantext import clean\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim, spacy, logging, warnings\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['https_www','seems_like','do','not','imgur','tkg','https','http','could','www','com','ever','doesnt_seem',\n",
    "                  'xxxx','else','would','also','ea','&amp','#x200B','oh','etc','yeah','nan','however','even','dont_know','sa',\n",
    "                  \"looks_like\",'especially','may','sounds_like'])\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dffb92f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18580, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>full_link</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>num_of_comments</th>\n",
       "      <th>permalink</th>\n",
       "      <th>flair</th>\n",
       "      <th>comment_msg</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4lx0dn</td>\n",
       "      <td>Alexa as an Android app. Who needs the Alexa d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/alexa/comments/4lx0dn...</td>\n",
       "      <td>layboy</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-06-01 03:25:15</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/alexa/comments/4lx0dn/alexa_as_an_android_a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>Alexa as an Android app. Who needs the Alexa d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  post_id                                              title selftext  \\\n",
       "0  4lx0dn  Alexa as an Android app. Who needs the Alexa d...      NaN   \n",
       "\n",
       "                                           full_link  author  score  \\\n",
       "0  https://www.reddit.com/r/alexa/comments/4lx0dn...  layboy      2   \n",
       "\n",
       "          publish_date  num_of_comments  \\\n",
       "0  2016-06-01 03:25:15                0   \n",
       "\n",
       "                                           permalink  flair comment_msg  \\\n",
       "0  /r/alexa/comments/4lx0dn/alexa_as_an_android_a...    NaN     ['nan']   \n",
       "\n",
       "                                             content  \n",
       "0  Alexa as an Android app. Who needs the Alexa d...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LoadDataset\n",
    "df=pd.read_csv('alexa_merged.csv')\n",
    "print(df.shape)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac05b1f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>full_link</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>num_of_comments</th>\n",
       "      <th>permalink</th>\n",
       "      <th>flair</th>\n",
       "      <th>comment_msg</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4lx0dn</td>\n",
       "      <td>Alexa as an Android app. Who needs the Alexa d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/alexa/comments/4lx0dn...</td>\n",
       "      <td>layboy</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-06-01 03:25:15</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/alexa/comments/4lx0dn/alexa_as_an_android_a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>alexa as an android app who needs the alexa de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4m8rd3</td>\n",
       "      <td>Let Alexa transform Pebble Core into the comba...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/alexa/comments/4m8rd3...</td>\n",
       "      <td>nnrR0b0t</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-06-03 02:59:42</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/alexa/comments/4m8rd3/let_alexa_transform_p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>let alexa transform pebble core into the comba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4me8xk</td>\n",
       "      <td>Sample Alexa Custom Skill for BART train times...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/alexa/comments/4me8xk...</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-04 02:19:44</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/alexa/comments/4me8xk/sample_alexa_custom_s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>sle alexa custom skill for bart train times in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4meeyz</td>\n",
       "      <td>Sample Alexa Custom Skill for SF BART transit ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/alexa/comments/4meeyz...</td>\n",
       "      <td>simonprickett</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-06-04 02:55:29</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/alexa/comments/4meeyz/sample_alexa_custom_s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>sle alexa custom skill for sf bart transit in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4mghpo</td>\n",
       "      <td>Alexa on pebble watches</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/alexa/comments/4mghpo...</td>\n",
       "      <td>layboy</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-06-04 11:01:10</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/alexa/comments/4mghpo/alexa_on_pebble_watches/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>alexa on pebble watches</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18575</td>\n",
       "      <td>np0tuf</td>\n",
       "      <td>How is a post deleted before it ever actually ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/alexa/comments/np0tuf...</td>\n",
       "      <td>Stamp_My_Art</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-05-31 19:05:32</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/alexa/comments/np0tuf/how_is_a_post_deleted...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>how is a post deleted before it ever actually ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18576</td>\n",
       "      <td>np0vru</td>\n",
       "      <td>Issue when turning on a lamp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/alexa/comments/np0vru...</td>\n",
       "      <td>fiorenzoalumide</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-05-31 19:08:43</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/alexa/comments/np0vru/issue_when_turning_on...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>issue when turning on a l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18577</td>\n",
       "      <td>np47mn</td>\n",
       "      <td>Why does Alexa think my AC is a thermostat and...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/alexa/comments/np47mn...</td>\n",
       "      <td>stgleason</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-05-31 22:06:50</td>\n",
       "      <td>9</td>\n",
       "      <td>/r/alexa/comments/np47mn/why_does_alexa_think_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['So, I recently reconfigured my network and c...</td>\n",
       "      <td>why does alexa think my ac is a thermostat and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18578</td>\n",
       "      <td>np5p0z</td>\n",
       "      <td>Music not working when using Alexa with a trav...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/alexa/comments/np5p0z...</td>\n",
       "      <td>bznelson91</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-05-31 23:14:44</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/alexa/comments/np5p0z/music_not_working_whe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>music not working when using alexa with a trav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18579</td>\n",
       "      <td>np6dem</td>\n",
       "      <td>How to Change Default Sound on Alarm?</td>\n",
       "      <td>A few nights ago I mumbled something at Alexa ...</td>\n",
       "      <td>https://www.reddit.com/r/alexa/comments/np6dem...</td>\n",
       "      <td>heresthe-thing</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-05-31 23:44:56</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/alexa/comments/np6dem/how_to_change_default...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['When i asked Alexa \"how do I change my alarm...</td>\n",
       "      <td>how to change default sound on alarm a few nig...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18580 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      post_id                                              title  \\\n",
       "0      4lx0dn  Alexa as an Android app. Who needs the Alexa d...   \n",
       "1      4m8rd3  Let Alexa transform Pebble Core into the comba...   \n",
       "2      4me8xk  Sample Alexa Custom Skill for BART train times...   \n",
       "3      4meeyz  Sample Alexa Custom Skill for SF BART transit ...   \n",
       "4      4mghpo                            Alexa on pebble watches   \n",
       "...       ...                                                ...   \n",
       "18575  np0tuf  How is a post deleted before it ever actually ...   \n",
       "18576  np0vru                       Issue when turning on a lamp   \n",
       "18577  np47mn  Why does Alexa think my AC is a thermostat and...   \n",
       "18578  np5p0z  Music not working when using Alexa with a trav...   \n",
       "18579  np6dem              How to Change Default Sound on Alarm?   \n",
       "\n",
       "                                                selftext  \\\n",
       "0                                                    NaN   \n",
       "1                                                    NaN   \n",
       "2                                                    NaN   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "18575                                                NaN   \n",
       "18576                                                NaN   \n",
       "18577                                                NaN   \n",
       "18578                                                NaN   \n",
       "18579  A few nights ago I mumbled something at Alexa ...   \n",
       "\n",
       "                                               full_link           author  \\\n",
       "0      https://www.reddit.com/r/alexa/comments/4lx0dn...           layboy   \n",
       "1      https://www.reddit.com/r/alexa/comments/4m8rd3...         nnrR0b0t   \n",
       "2      https://www.reddit.com/r/alexa/comments/4me8xk...        [deleted]   \n",
       "3      https://www.reddit.com/r/alexa/comments/4meeyz...    simonprickett   \n",
       "4      https://www.reddit.com/r/alexa/comments/4mghpo...           layboy   \n",
       "...                                                  ...              ...   \n",
       "18575  https://www.reddit.com/r/alexa/comments/np0tuf...     Stamp_My_Art   \n",
       "18576  https://www.reddit.com/r/alexa/comments/np0vru...  fiorenzoalumide   \n",
       "18577  https://www.reddit.com/r/alexa/comments/np47mn...        stgleason   \n",
       "18578  https://www.reddit.com/r/alexa/comments/np5p0z...       bznelson91   \n",
       "18579  https://www.reddit.com/r/alexa/comments/np6dem...   heresthe-thing   \n",
       "\n",
       "       score         publish_date  num_of_comments  \\\n",
       "0          2  2016-06-01 03:25:15                0   \n",
       "1          4  2016-06-03 02:59:42                0   \n",
       "2          1  2016-06-04 02:19:44                0   \n",
       "3          3  2016-06-04 02:55:29                0   \n",
       "4          2  2016-06-04 11:01:10                0   \n",
       "...      ...                  ...              ...   \n",
       "18575      1  2021-05-31 19:05:32                0   \n",
       "18576      1  2021-05-31 19:08:43                0   \n",
       "18577      1  2021-05-31 22:06:50                9   \n",
       "18578      1  2021-05-31 23:14:44                0   \n",
       "18579      1  2021-05-31 23:44:56                1   \n",
       "\n",
       "                                               permalink  flair  \\\n",
       "0      /r/alexa/comments/4lx0dn/alexa_as_an_android_a...    NaN   \n",
       "1      /r/alexa/comments/4m8rd3/let_alexa_transform_p...    NaN   \n",
       "2      /r/alexa/comments/4me8xk/sample_alexa_custom_s...    NaN   \n",
       "3      /r/alexa/comments/4meeyz/sample_alexa_custom_s...    NaN   \n",
       "4      /r/alexa/comments/4mghpo/alexa_on_pebble_watches/    NaN   \n",
       "...                                                  ...    ...   \n",
       "18575  /r/alexa/comments/np0tuf/how_is_a_post_deleted...    NaN   \n",
       "18576  /r/alexa/comments/np0vru/issue_when_turning_on...    NaN   \n",
       "18577  /r/alexa/comments/np47mn/why_does_alexa_think_...    NaN   \n",
       "18578  /r/alexa/comments/np5p0z/music_not_working_whe...    NaN   \n",
       "18579  /r/alexa/comments/np6dem/how_to_change_default...    NaN   \n",
       "\n",
       "                                             comment_msg  \\\n",
       "0                                                ['nan']   \n",
       "1                                                ['nan']   \n",
       "2                                                ['nan']   \n",
       "3                                                ['nan']   \n",
       "4                                                ['nan']   \n",
       "...                                                  ...   \n",
       "18575                                            ['nan']   \n",
       "18576                                            ['nan']   \n",
       "18577  ['So, I recently reconfigured my network and c...   \n",
       "18578                                            ['nan']   \n",
       "18579  ['When i asked Alexa \"how do I change my alarm...   \n",
       "\n",
       "                                                 content  \n",
       "0      alexa as an android app who needs the alexa de...  \n",
       "1      let alexa transform pebble core into the comba...  \n",
       "2      sle alexa custom skill for bart train times in...  \n",
       "3      sle alexa custom skill for sf bart transit in ...  \n",
       "4                               alexa on pebble watches   \n",
       "...                                                  ...  \n",
       "18575  how is a post deleted before it ever actually ...  \n",
       "18576                         issue when turning on a l   \n",
       "18577  why does alexa think my ac is a thermostat and...  \n",
       "18578  music not working when using alexa with a trav...  \n",
       "18579  how to change default sound on alarm a few nig...  \n",
       "\n",
       "[18580 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import preprocessor as p\n",
    "p.set_options(p.OPT.URL, p.OPT.EMOJI)\n",
    "\n",
    "def preprocess_tweet(row):\n",
    "    text = row['content']\n",
    "    text = text.replace('r/','')\n",
    "    text = p.clean(text)\n",
    "    text = clean(text,     \n",
    "                 fix_unicode=True,              # fix various unicode errors\n",
    "                 to_ascii=True,                 # transliterate to closest ASCII representation\n",
    "                 lower=True,                    # lowercase text\n",
    "                 no_line_breaks=True,           # fully strip line breaks as opposed to only normalizing them\n",
    "                 no_urls=True,                  # replace all URLs with a special token\n",
    "                 no_emails=True,                # replace all email addresses with a special token\n",
    "                 no_phone_numbers=True,         # replace all phone numbers with a special token\n",
    "                 no_numbers=True,               # replace all numbers with a special token\n",
    "                 no_digits=True,                # replace all digits with a special token\n",
    "                 no_currency_symbols=True,      # replace all currency symbols with a special token\n",
    "                 no_punct=True,                 # remove punctuations\n",
    "                 lang=\"en\",                     # set to 'de' for German special handling\n",
    "                 replace_with_punct=\"\",          # instead of removing punctuations you may replace them\n",
    "                 replace_with_url=\"\",\n",
    "                 replace_with_email=\"\",\n",
    "                 replace_with_phone_number=\"\",\n",
    "                 replace_with_number=\"\",\n",
    "                 replace_with_digit=\"\",\n",
    "                 replace_with_currency_symbol=\"\"\n",
    "                )\n",
    "    text = text.replace('amp','')\n",
    "    text = text.replace('nan','')\n",
    "    return text\n",
    "\n",
    "df['content'] = df.apply(preprocess_tweet, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2f8d1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['alexa', 'as', 'an', 'android', 'app', 'who', 'needs', 'the', 'alexa', 'devices']]\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sent in sentences:\n",
    "        sent = re.sub(r'http\\S+', '', sent) # remove http\n",
    "        sent = re.sub(r'https\\S+', '', sent) # remove https\n",
    "        sent = re.sub('<[^>]+>', '', sent) # remove HTML tags\n",
    "        sent = re.sub('<[^<]+?>', '', sent)\n",
    "        sent = re.sub('\\S*@\\S*\\s?', '', sent)  # remove emails\n",
    "        sent = re.sub('\\s+', ' ', sent)  # remove newline chars\n",
    "        sent = re.sub(\"\\'\", \"\", sent)  # remove single quotes\n",
    "        sent = re.sub(r'[^\\w\\s]','',sent) # remove punctuations\n",
    "        sent = gensim.utils.simple_preprocess(str(sent), min_len=2, deacc=True) \n",
    "        \n",
    "        yield(sent)  \n",
    "\n",
    "# # Convert to list\n",
    "data = df.content.values.tolist()\n",
    "data_words = list(sent_to_words(data))\n",
    "print(data_words[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9a6d830",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['alexa', 'android_app', 'need', 'alexa_device'], ['let_alexa', 'transform', 'pebble', 'core', 'combadge', 'dream']]\n"
     ]
    }
   ],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=1,delimiter='_') # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=1, delimiter='_')  \n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# Tag   Meaning                English Examples\n",
    "# ADJ   adjective              new, good, high, special, big, local\n",
    "# ADP   adposition             on, of, at, with, by, into, under\n",
    "# ADV   adverb                 really, already, still, early, now\n",
    "# CONJ  conjunction            and, or, but, if, while, although\n",
    "# DET   determiner, article    the, a, some, most, every, no, which\n",
    "# NOUN  noun                   year, home, costs, time, Africa\n",
    "# NUM   numeral                twenty-four, fourth, 1991, 14:24\n",
    "# PRT   particle               at, on, out, over per, that, up, with\n",
    "# PRON  pronoun                he, their, her, its, my, I, us\n",
    "# VERB  verb                   is, say, told, given, playing, would\n",
    "# .     punctuation marks      . , ; !\n",
    "# X     other                  ersatz, esprit, dunno, gr8, univeristy\n",
    "\n",
    "# def process_words(texts, stop_words=stop_words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "def process_words(texts, stop_words=stop_words, disallowed_postags=['ADP', 'CONJ', 'DET', 'NUM', 'PRT','PRON','.','X']):\n",
    "    \"\"\"Remove Stopwords, Form Bigrams, Trigrams and Lemmatization\"\"\"\n",
    "    texts = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "    texts = [bigram_mod[doc] for doc in texts]\n",
    "    texts = [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "    texts_out = []\n",
    "    nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ not in disallowed_postags])\n",
    "#         texts_out.append([token.lemma_ for token in doc])\n",
    "    # remove stopwords once more after lemmatization\n",
    "    texts_out = [[word for word in simple_preprocess(str(doc), max_len=20) if word not in stop_words] for doc in texts_out] \n",
    "    return texts_out\n",
    "\n",
    "data_ready = process_words(data_words)  # processed Text Data!\n",
    "print(data_ready[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbed0491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['alexa', 'android_app', 'need', 'alexa_device'], ['let_alexa', 'transform', 'pebble', 'core', 'combadge', 'dream']]\n"
     ]
    }
   ],
   "source": [
    "print(data_ready[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ad78bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in initital documents: 47597\n",
      "Number of unique words after removing rare and common words: 1170\n",
      "Number of documents: 18580\n"
     ]
    }
   ],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Create Dictionary\n",
    "id2word = Dictionary(data_ready)\n",
    "print('Number of unique words in initital documents:', len(id2word))\n",
    "\n",
    "# Filter out words that occur less than 0.5% documents, or more than 20% of the documents.\n",
    "id2word.filter_extremes(no_below = (round(((len(data_ready))*0.005))), no_above = 0.99)\n",
    "print('Number of unique words after removing rare and common words:', len(id2word))\n",
    "\n",
    "# Create Corpus: Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in data_ready]\n",
    "print('Number of documents: %d' % len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53d1a00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word.save(\"corpus_dict/dict\")\n",
    "corpora.MmCorpus.serialize(\"corpus_dict/corpus\", corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cab56590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>full_link</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>num_of_comments</th>\n",
       "      <th>permalink</th>\n",
       "      <th>flair</th>\n",
       "      <th>comment_msg</th>\n",
       "      <th>content</th>\n",
       "      <th>tokenz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4lx0dn</td>\n",
       "      <td>Alexa as an Android app. Who needs the Alexa d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/alexa/comments/4lx0dn...</td>\n",
       "      <td>layboy</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-06-01 03:25:15</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/alexa/comments/4lx0dn/alexa_as_an_android_a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>alexa as an android app who needs the alexa de...</td>\n",
       "      <td>[alexa, alexa_device, need]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  post_id                                              title selftext  \\\n",
       "0  4lx0dn  Alexa as an Android app. Who needs the Alexa d...      NaN   \n",
       "\n",
       "                                           full_link  author  score  \\\n",
       "0  https://www.reddit.com/r/alexa/comments/4lx0dn...  layboy      2   \n",
       "\n",
       "          publish_date  num_of_comments  \\\n",
       "0  2016-06-01 03:25:15                0   \n",
       "\n",
       "                                           permalink  flair comment_msg  \\\n",
       "0  /r/alexa/comments/4lx0dn/alexa_as_an_android_a...    NaN     ['nan']   \n",
       "\n",
       "                                             content  \\\n",
       "0  alexa as an android app who needs the alexa de...   \n",
       "\n",
       "                        tokenz  \n",
       "0  [alexa, alexa_device, need]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokenz'] = [[(id2word[id]) for id, freq in cp] for cp in corpus[:]]\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bcbb9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('1_df_content_tokenz.csv',index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "377410c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('alexa', 1), ('alexa_device', 1), ('need', 1)]]\n"
     ]
    }
   ],
   "source": [
    "print([[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8e87ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #tf-idf\n",
    "# from gensim.models import TfidfModel\n",
    "\n",
    "# # Create Dictionary\n",
    "# from gensim import models\n",
    "\n",
    "# tfidf = models.TfidfModel(corpus, id2word=id2word)  # step 1 -- initialize a model\n",
    "# corpus = tfidf[corpus]\n",
    "# for doc in corpus:\n",
    "#     pprint(doc)\n",
    "#     break\n",
    "\n",
    "# # print('Number of unique tokens: %d' % len(id2word))\n",
    "# # print('Number of documents: %d' % len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1de07f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# topWords = {}\n",
    "# for doc in corpus:\n",
    "#     for iWord, tf_idf in doc:\n",
    "#         if iWord not in topWords:\n",
    "#             topWords[iWord] = 0\n",
    "\n",
    "#         if tf_idf > topWords[iWord]:\n",
    "#             topWords[iWord] = tf_idf\n",
    "# sum = 0\n",
    "# term = []\n",
    "# for i, item in enumerate(sorted(topWords.items(), key=lambda x: x[1], reverse=True), 1):\n",
    "# #     print(\"%2s: %-13s %s\" % (i, id2word[item[0]], item[1]))\n",
    "#     term.append(id2word[item[0]])\n",
    "#     sum += item[1]\n",
    "# #     if i == 100: break\n",
    "# # print (sum)\n",
    "# mean = sum/i\n",
    "# print ('Mean of tf-idf score: ' + str(mean))\n",
    "# # print (term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a549dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #tf-idf\n",
    "# from gensim.models import TfidfModel\n",
    "\n",
    "# # Create Dictionary\n",
    "# from gensim import models\n",
    "\n",
    "# low_value = 0.271734994034526\n",
    "# low_value_words = []\n",
    "\n",
    "# tfidf = models.TfidfModel(corpus, id2word=id2word)  # step 1 -- initialize a model\n",
    "# corpus = tfidf[corpus]\n",
    "# for doc in corpus:\n",
    "#     low_value_words += [id for id, value in tfidf[doc] if value < low_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5c4bd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# id2word.filter_tokens(bad_ids=low_value_words)\n",
    "# print('Number of filtered unique tokens: %d' % len(id2word))\n",
    "# print('Number of documents: %d' % len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8c68b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus = [id2word.doc2bow(doc) for doc in data_ready]\n",
    "# corpus = tfidf[corpus]\n",
    "# for doc in corpus:\n",
    "#     pprint(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbb657bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print([[(id2word[id], freq) for id, freq in cp] for cp in corpus[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20c1813f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build LDA model\n",
    "# lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "#                                            id2word=id2word,\n",
    "#                                            num_topics=10)\n",
    "\n",
    "# pprint(lda_model.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "deb6e28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(corpus, dictionary, num_topics, a, b):\n",
    "    \n",
    "    lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                                id2word=id2word,\n",
    "                                                num_topics=num_topics, \n",
    "                                                random_state=100,\n",
    "                                                chunksize=100,\n",
    "                                                passes=40,\n",
    "                                                iterations=1000,\n",
    "                                                alpha=a,\n",
    "                                                eta=1/num_topics,\n",
    "                                                eval_every=None)\n",
    "    \n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=df['tokenz'], dictionary=id2word, coherence='c_v')\n",
    "    \n",
    "    return coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c597e4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0.01\n",
      "0.2\n",
      "0.6332098218190001\n",
      "5\n",
      "0.05\n",
      "0.2\n",
      "0.6280225817485954\n",
      "5\n",
      "0.1\n",
      "0.2\n",
      "0.6284308781661567\n",
      "5\n",
      "0.2\n",
      "0.2\n",
      "0.6209430848367596\n",
      "5\n",
      "0.5\n",
      "0.2\n",
      "0.6569419559467187\n",
      "5\n",
      "1\n",
      "0.2\n",
      "0.644788659013701\n",
      "10\n",
      "0.01\n",
      "0.1\n",
      "0.5832443382600146\n",
      "10\n",
      "0.05\n",
      "0.1\n",
      "0.5808886033045311\n",
      "10\n",
      "0.1\n",
      "0.1\n",
      "0.5805628030106785\n",
      "10\n",
      "0.2\n",
      "0.1\n",
      "0.5944779488300023\n",
      "10\n",
      "0.5\n",
      "0.1\n",
      "0.6188388138776549\n",
      "10\n",
      "1\n",
      "0.1\n",
      "0.6533911858489322\n",
      "20\n",
      "0.01\n",
      "0.05\n",
      "0.5751609996065101\n",
      "20\n",
      "0.05\n",
      "0.05\n",
      "0.5738476396599087\n",
      "20\n",
      "0.1\n",
      "0.05\n",
      "0.5732348187383194\n",
      "20\n",
      "0.2\n",
      "0.05\n",
      "0.5613988757020796\n",
      "20\n",
      "0.5\n",
      "0.05\n",
      "0.6159233463283882\n",
      "20\n",
      "1\n",
      "0.05\n",
      "0.6348736288013815\n",
      "30\n",
      "0.01\n",
      "0.03333333333333333\n",
      "0.5223318713542239\n",
      "30\n",
      "0.05\n",
      "0.03333333333333333\n",
      "0.5372625551335076\n",
      "30\n",
      "0.1\n",
      "0.03333333333333333\n",
      "0.5319188701208576\n",
      "30\n",
      "0.2\n",
      "0.03333333333333333\n",
      "0.5387423235417802\n",
      "30\n",
      "0.5\n",
      "0.03333333333333333\n",
      "0.5459476996815646\n",
      "30\n",
      "1\n",
      "0.03333333333333333\n",
      "0.5510036885053755\n"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "\n",
    "topics_range = [5,10,20,30]\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = [.01,.05,.1,.2,.5,1]\n",
    "# alpha.append('symmetric')\n",
    "# alpha.append('asymmetric')\n",
    "\n",
    "# Beta parameter\n",
    "# beta = [1/num_topics]\n",
    "# beta.append('symmetric')\n",
    "# beta.append('auto')\n",
    "\n",
    "model_results = {'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "# iterate through number of topics\n",
    "for num_topics in topics_range:\n",
    "    # iterate through alpha values\n",
    "    for a in alpha:\n",
    "        # iterare through beta values\n",
    "#         for b in beta:\n",
    "        # get the coherence score for the given parameters\n",
    "        cv = compute_coherence_values(corpus=corpus, dictionary=id2word, \n",
    "                                      num_topics=num_topics, a=a, b=1/num_topics)\n",
    "        # Save the model results\n",
    "        model_results['Topics'].append(num_topics)\n",
    "        model_results['Alpha'].append(a)\n",
    "        model_results['Beta'].append(1/num_topics)\n",
    "        model_results['Coherence'].append(cv)\n",
    "        print (num_topics)\n",
    "        print (a)\n",
    "        print (1/num_topics)\n",
    "        print (cv)\n",
    "\n",
    "model_results_1 = pd.DataFrame(model_results)\n",
    "model_results_1.to_csv('tuning/00_lda_tuning_results.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97e38d64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0.01\n",
      "0.2\n",
      "0.6332098218190001\n",
      "5\n",
      "0.05\n",
      "0.2\n",
      "0.6280225817485954\n",
      "5\n",
      "0.1\n",
      "0.2\n",
      "0.6284308781661567\n",
      "5\n",
      "0.2\n",
      "0.2\n",
      "0.6209430848367596\n",
      "5\n",
      "0.5\n",
      "0.2\n",
      "0.6569419559467187\n",
      "5\n",
      "1\n",
      "0.2\n",
      "0.644788659013701\n",
      "10\n",
      "0.01\n",
      "0.1\n",
      "0.5832443382600146\n",
      "10\n",
      "0.05\n",
      "0.1\n",
      "0.5808886033045311\n",
      "10\n",
      "0.1\n",
      "0.1\n",
      "0.5805628030106785\n",
      "10\n",
      "0.2\n",
      "0.1\n",
      "0.5944779488300023\n",
      "10\n",
      "0.5\n",
      "0.1\n",
      "0.6188388138776549\n",
      "10\n",
      "1\n",
      "0.1\n",
      "0.6533911858489322\n",
      "20\n",
      "0.01\n",
      "0.05\n",
      "0.5751609996065101\n",
      "20\n",
      "0.05\n",
      "0.05\n",
      "0.5738476396599087\n",
      "20\n",
      "0.1\n",
      "0.05\n",
      "0.5732348187383194\n",
      "20\n",
      "0.2\n",
      "0.05\n",
      "0.5613988757020796\n",
      "20\n",
      "0.5\n",
      "0.05\n",
      "0.6159233463283882\n",
      "20\n",
      "1\n",
      "0.05\n",
      "0.6348736288013815\n",
      "30\n",
      "0.01\n",
      "0.03333333333333333\n",
      "0.5223318713542239\n",
      "30\n",
      "0.05\n",
      "0.03333333333333333\n",
      "0.5372625551335076\n",
      "30\n",
      "0.1\n",
      "0.03333333333333333\n",
      "0.5319188701208576\n",
      "30\n",
      "0.2\n",
      "0.03333333333333333\n",
      "0.5387423235417802\n",
      "30\n",
      "0.5\n",
      "0.03333333333333333\n",
      "0.5459476996815646\n",
      "30\n",
      "1\n",
      "0.03333333333333333\n",
      "0.5510036885053755\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "\n",
    "topics_range = [5,10,20,30]\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = [.01,.05,.1,.2,.5,1]\n",
    "# alpha.append('symmetric')\n",
    "# alpha.append('asymmetric')\n",
    "\n",
    "# Beta parameter\n",
    "# beta = [1/num_topics]\n",
    "# beta.append('symmetric')\n",
    "# beta.append('auto')\n",
    "\n",
    "model_results = {'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "# iterate through number of topics\n",
    "for num_topics in topics_range:\n",
    "    # iterate through alpha values\n",
    "    for a in alpha:\n",
    "        # iterare through beta values\n",
    "#         for b in beta:\n",
    "        # get the coherence score for the given parameters\n",
    "        cv = compute_coherence_values(corpus=corpus, dictionary=id2word, \n",
    "                                      num_topics=num_topics, a=a, b=1/num_topics)\n",
    "        # Save the model results\n",
    "        model_results['Topics'].append(num_topics)\n",
    "        model_results['Alpha'].append(a)\n",
    "        model_results['Beta'].append(1/num_topics)\n",
    "        model_results['Coherence'].append(cv)\n",
    "        print (num_topics)\n",
    "        print (a)\n",
    "        print (1/num_topics)\n",
    "        print (cv)\n",
    "\n",
    "model_results_2 = pd.DataFrame(model_results)\n",
    "model_results_2.to_csv('tuning/11_lda_tuning_results.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16f2b3c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0.01\n",
      "0.2\n",
      "0.6332098218190001\n",
      "5\n",
      "0.05\n",
      "0.2\n",
      "0.6280225817485954\n",
      "5\n",
      "0.1\n",
      "0.2\n",
      "0.6284308781661567\n",
      "5\n",
      "0.2\n",
      "0.2\n",
      "0.6209430848367596\n",
      "5\n",
      "0.5\n",
      "0.2\n",
      "0.6569419559467187\n",
      "5\n",
      "1\n",
      "0.2\n",
      "0.644788659013701\n",
      "10\n",
      "0.01\n",
      "0.1\n",
      "0.5832443382600146\n",
      "10\n",
      "0.05\n",
      "0.1\n",
      "0.5808886033045311\n",
      "10\n",
      "0.1\n",
      "0.1\n",
      "0.5805628030106785\n",
      "10\n",
      "0.2\n",
      "0.1\n",
      "0.5944779488300023\n",
      "10\n",
      "0.5\n",
      "0.1\n",
      "0.6188388138776549\n",
      "10\n",
      "1\n",
      "0.1\n",
      "0.6533911858489322\n",
      "20\n",
      "0.01\n",
      "0.05\n",
      "0.5751609996065101\n",
      "20\n",
      "0.05\n",
      "0.05\n",
      "0.5738476396599087\n",
      "20\n",
      "0.1\n",
      "0.05\n",
      "0.5732348187383194\n",
      "20\n",
      "0.2\n",
      "0.05\n",
      "0.5613988757020796\n",
      "20\n",
      "0.5\n",
      "0.05\n",
      "0.6159233463283882\n",
      "20\n",
      "1\n",
      "0.05\n",
      "0.6348736288013815\n",
      "30\n",
      "0.01\n",
      "0.03333333333333333\n",
      "0.5223318713542239\n",
      "30\n",
      "0.05\n",
      "0.03333333333333333\n",
      "0.5372625551335076\n",
      "30\n",
      "0.1\n",
      "0.03333333333333333\n",
      "0.5319188701208576\n",
      "30\n",
      "0.2\n",
      "0.03333333333333333\n",
      "0.5387423235417802\n",
      "30\n",
      "0.5\n",
      "0.03333333333333333\n",
      "0.5459476996815646\n",
      "30\n",
      "1\n",
      "0.03333333333333333\n",
      "0.5510036885053755\n"
     ]
    }
   ],
   "source": [
    "# 3\n",
    "\n",
    "topics_range = [5,10,20,30]\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = [.01,.05,.1,.2,.5,1]\n",
    "# alpha.append('symmetric')\n",
    "# alpha.append('asymmetric')\n",
    "\n",
    "# Beta parameter\n",
    "# beta = [1/num_topics]\n",
    "# beta.append('symmetric')\n",
    "# beta.append('auto')\n",
    "\n",
    "model_results = {'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "# iterate through number of topics\n",
    "for num_topics in topics_range:\n",
    "    # iterate through alpha values\n",
    "    for a in alpha:\n",
    "        # iterare through beta values\n",
    "#         for b in beta:\n",
    "        # get the coherence score for the given parameters\n",
    "        cv = compute_coherence_values(corpus=corpus, dictionary=id2word, \n",
    "                                      num_topics=num_topics, a=a, b=1/num_topics)\n",
    "        # Save the model results\n",
    "        model_results['Topics'].append(num_topics)\n",
    "        model_results['Alpha'].append(a)\n",
    "        model_results['Beta'].append(1/num_topics)\n",
    "        model_results['Coherence'].append(cv)\n",
    "        print (num_topics)\n",
    "        print (a)\n",
    "        print (1/num_topics)\n",
    "        print (cv)\n",
    "\n",
    "model_results_3 = pd.DataFrame(model_results)\n",
    "model_results_3.to_csv('tuning/22_lda_tuning_results.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e996fa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0.01\n",
      "0.2\n",
      "0.6332098218190001\n",
      "5\n",
      "0.05\n",
      "0.2\n",
      "0.6280225817485954\n",
      "5\n",
      "0.1\n",
      "0.2\n",
      "0.6284308781661567\n",
      "5\n",
      "0.2\n",
      "0.2\n",
      "0.6209430848367596\n",
      "5\n",
      "0.5\n",
      "0.2\n",
      "0.6569419559467187\n",
      "5\n",
      "1\n",
      "0.2\n",
      "0.644788659013701\n",
      "10\n",
      "0.01\n",
      "0.1\n",
      "0.5832443382600146\n",
      "10\n",
      "0.05\n",
      "0.1\n",
      "0.5808886033045311\n",
      "10\n",
      "0.1\n",
      "0.1\n",
      "0.5805628030106785\n",
      "10\n",
      "0.2\n",
      "0.1\n",
      "0.5944779488300023\n",
      "10\n",
      "0.5\n",
      "0.1\n",
      "0.6188388138776549\n",
      "10\n",
      "1\n",
      "0.1\n",
      "0.6533911858489322\n",
      "20\n",
      "0.01\n",
      "0.05\n",
      "0.5751609996065101\n",
      "20\n",
      "0.05\n",
      "0.05\n",
      "0.5738476396599087\n",
      "20\n",
      "0.1\n",
      "0.05\n",
      "0.5732348187383194\n",
      "20\n",
      "0.2\n",
      "0.05\n",
      "0.5613988757020796\n",
      "20\n",
      "0.5\n",
      "0.05\n",
      "0.6159233463283882\n",
      "20\n",
      "1\n",
      "0.05\n",
      "0.6348736288013815\n",
      "30\n",
      "0.01\n",
      "0.03333333333333333\n",
      "0.5223318713542239\n",
      "30\n",
      "0.05\n",
      "0.03333333333333333\n",
      "0.5372625551335076\n",
      "30\n",
      "0.1\n",
      "0.03333333333333333\n",
      "0.5319188701208576\n",
      "30\n",
      "0.2\n",
      "0.03333333333333333\n",
      "0.5387423235417802\n",
      "30\n",
      "0.5\n",
      "0.03333333333333333\n",
      "0.5459476996815646\n",
      "30\n",
      "1\n",
      "0.03333333333333333\n",
      "0.5510036885053755\n"
     ]
    }
   ],
   "source": [
    "# 4\n",
    "\n",
    "topics_range = [5,10,20,30]\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = [.01,.05,.1,.2,.5,1]\n",
    "# alpha.append('symmetric')\n",
    "# alpha.append('asymmetric')\n",
    "\n",
    "# Beta parameter\n",
    "# beta = [1/num_topics]\n",
    "# beta.append('symmetric')\n",
    "# beta.append('auto')\n",
    "\n",
    "model_results = {'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "# iterate through number of topics\n",
    "for num_topics in topics_range:\n",
    "    # iterate through alpha values\n",
    "    for a in alpha:\n",
    "        # iterare through beta values\n",
    "#         for b in beta:\n",
    "        # get the coherence score for the given parameters\n",
    "        cv = compute_coherence_values(corpus=corpus, dictionary=id2word, \n",
    "                                      num_topics=num_topics, a=a, b=1/num_topics)\n",
    "        # Save the model results\n",
    "        model_results['Topics'].append(num_topics)\n",
    "        model_results['Alpha'].append(a)\n",
    "        model_results['Beta'].append(1/num_topics)\n",
    "        model_results['Coherence'].append(cv)\n",
    "        print (num_topics)\n",
    "        print (a)\n",
    "        print (1/num_topics)\n",
    "        print (cv)\n",
    "\n",
    "model_results_4 = pd.DataFrame(model_results)\n",
    "model_results_4.to_csv('tuning/33_lda_tuning_results.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10d0c1e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0.01\n",
      "0.2\n",
      "0.6332098218190001\n",
      "5\n",
      "0.05\n",
      "0.2\n",
      "0.6280225817485954\n",
      "5\n",
      "0.1\n",
      "0.2\n",
      "0.6284308781661567\n",
      "5\n",
      "0.2\n",
      "0.2\n",
      "0.6209430848367596\n",
      "5\n",
      "0.5\n",
      "0.2\n",
      "0.6569419559467187\n",
      "5\n",
      "1\n",
      "0.2\n",
      "0.644788659013701\n",
      "10\n",
      "0.01\n",
      "0.1\n",
      "0.5832443382600146\n",
      "10\n",
      "0.05\n",
      "0.1\n",
      "0.5808886033045311\n",
      "10\n",
      "0.1\n",
      "0.1\n",
      "0.5805628030106785\n",
      "10\n",
      "0.2\n",
      "0.1\n",
      "0.5944779488300023\n",
      "10\n",
      "0.5\n",
      "0.1\n",
      "0.6188388138776549\n",
      "10\n",
      "1\n",
      "0.1\n",
      "0.6533911858489322\n",
      "20\n",
      "0.01\n",
      "0.05\n",
      "0.5751609996065101\n",
      "20\n",
      "0.05\n",
      "0.05\n",
      "0.5738476396599087\n",
      "20\n",
      "0.1\n",
      "0.05\n",
      "0.5732348187383194\n",
      "20\n",
      "0.2\n",
      "0.05\n",
      "0.5613988757020796\n",
      "20\n",
      "0.5\n",
      "0.05\n",
      "0.6159233463283882\n",
      "20\n",
      "1\n",
      "0.05\n",
      "0.6348736288013815\n",
      "30\n",
      "0.01\n",
      "0.03333333333333333\n",
      "0.5223318713542239\n",
      "30\n",
      "0.05\n",
      "0.03333333333333333\n",
      "0.5372625551335076\n",
      "30\n",
      "0.1\n",
      "0.03333333333333333\n",
      "0.5319188701208576\n",
      "30\n",
      "0.2\n",
      "0.03333333333333333\n",
      "0.5387423235417802\n",
      "30\n",
      "0.5\n",
      "0.03333333333333333\n",
      "0.5459476996815646\n",
      "30\n",
      "1\n",
      "0.03333333333333333\n",
      "0.5510036885053755\n"
     ]
    }
   ],
   "source": [
    "# 5\n",
    "\n",
    "topics_range = [5,10,20,30]\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = [.01,.05,.1,.2,.5,1]\n",
    "# alpha.append('symmetric')\n",
    "# alpha.append('asymmetric')\n",
    "\n",
    "# Beta parameter\n",
    "# beta = [1/num_topics]\n",
    "# beta.append('symmetric')\n",
    "# beta.append('auto')\n",
    "\n",
    "model_results = {'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "# iterate through number of topics\n",
    "for num_topics in topics_range:\n",
    "    # iterate through alpha values\n",
    "    for a in alpha:\n",
    "        # iterare through beta values\n",
    "#         for b in beta:\n",
    "        # get the coherence score for the given parameters\n",
    "        cv = compute_coherence_values(corpus=corpus, dictionary=id2word, \n",
    "                                      num_topics=num_topics, a=a, b=1/num_topics)\n",
    "        # Save the model results\n",
    "        model_results['Topics'].append(num_topics)\n",
    "        model_results['Alpha'].append(a)\n",
    "        model_results['Beta'].append(1/num_topics)\n",
    "        model_results['Coherence'].append(cv)\n",
    "        print (num_topics)\n",
    "        print (a)\n",
    "        print (1/num_topics)\n",
    "        print (cv)\n",
    "\n",
    "model_results_5 = pd.DataFrame(model_results)\n",
    "model_results_5.to_csv('tuning/44_lda_tuning_results.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8b33fc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0.01\n",
      "0.2\n",
      "0.6332098218190001\n",
      "5\n",
      "0.05\n",
      "0.2\n",
      "0.6280225817485954\n",
      "5\n",
      "0.1\n",
      "0.2\n",
      "0.6284308781661567\n",
      "5\n",
      "0.2\n",
      "0.2\n",
      "0.6209430848367596\n",
      "5\n",
      "0.5\n",
      "0.2\n",
      "0.6569419559467187\n",
      "5\n",
      "1\n",
      "0.2\n",
      "0.644788659013701\n",
      "10\n",
      "0.01\n",
      "0.1\n",
      "0.5832443382600146\n",
      "10\n",
      "0.05\n",
      "0.1\n",
      "0.5808886033045311\n",
      "10\n",
      "0.1\n",
      "0.1\n",
      "0.5805628030106785\n",
      "10\n",
      "0.2\n",
      "0.1\n",
      "0.5944779488300023\n",
      "10\n",
      "0.5\n",
      "0.1\n",
      "0.6188388138776549\n",
      "10\n",
      "1\n",
      "0.1\n",
      "0.6533911858489322\n",
      "20\n",
      "0.01\n",
      "0.05\n",
      "0.5751609996065101\n",
      "20\n",
      "0.05\n",
      "0.05\n",
      "0.5738476396599087\n",
      "20\n",
      "0.1\n",
      "0.05\n",
      "0.5732348187383194\n",
      "20\n",
      "0.2\n",
      "0.05\n",
      "0.5613988757020796\n",
      "20\n",
      "0.5\n",
      "0.05\n",
      "0.6159233463283882\n",
      "20\n",
      "1\n",
      "0.05\n",
      "0.6348736288013815\n",
      "30\n",
      "0.01\n",
      "0.03333333333333333\n",
      "0.5223318713542239\n",
      "30\n",
      "0.05\n",
      "0.03333333333333333\n",
      "0.5372625551335076\n",
      "30\n",
      "0.1\n",
      "0.03333333333333333\n",
      "0.5319188701208576\n",
      "30\n",
      "0.2\n",
      "0.03333333333333333\n",
      "0.5387423235417802\n",
      "30\n",
      "0.5\n",
      "0.03333333333333333\n",
      "0.5459476996815646\n",
      "30\n",
      "1\n",
      "0.03333333333333333\n",
      "0.5510036885053755\n"
     ]
    }
   ],
   "source": [
    "# 6\n",
    "\n",
    "topics_range = [5,10,20,30]\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = [.01,.05,.1,.2,.5,1]\n",
    "# alpha.append('symmetric')\n",
    "# alpha.append('asymmetric')\n",
    "\n",
    "# Beta parameter\n",
    "# beta = [1/num_topics]\n",
    "# beta.append('symmetric')\n",
    "# beta.append('auto')\n",
    "\n",
    "model_results = {'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "# iterate through number of topics\n",
    "for num_topics in topics_range:\n",
    "    # iterate through alpha values\n",
    "    for a in alpha:\n",
    "        # iterare through beta values\n",
    "#         for b in beta:\n",
    "        # get the coherence score for the given parameters\n",
    "        cv = compute_coherence_values(corpus=corpus, dictionary=id2word, \n",
    "                                      num_topics=num_topics, a=a, b=1/num_topics)\n",
    "        # Save the model results\n",
    "        model_results['Topics'].append(num_topics)\n",
    "        model_results['Alpha'].append(a)\n",
    "        model_results['Beta'].append(1/num_topics)\n",
    "        model_results['Coherence'].append(cv)\n",
    "        print (num_topics)\n",
    "        print (a)\n",
    "        print (1/num_topics)\n",
    "        print (cv)\n",
    "\n",
    "model_results_6 = pd.DataFrame(model_results)\n",
    "model_results_6.to_csv('tuning/55_lda_tuning_results.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37a96b9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0.01\n",
      "0.2\n",
      "0.6332098218190001\n",
      "5\n",
      "0.05\n",
      "0.2\n",
      "0.6280225817485954\n",
      "5\n",
      "0.1\n",
      "0.2\n",
      "0.6284308781661567\n",
      "5\n",
      "0.2\n",
      "0.2\n",
      "0.6209430848367596\n",
      "5\n",
      "0.5\n",
      "0.2\n",
      "0.6569419559467187\n",
      "5\n",
      "1\n",
      "0.2\n",
      "0.644788659013701\n",
      "10\n",
      "0.01\n",
      "0.1\n",
      "0.5832443382600146\n",
      "10\n",
      "0.05\n",
      "0.1\n",
      "0.5808886033045311\n",
      "10\n",
      "0.1\n",
      "0.1\n",
      "0.5805628030106785\n",
      "10\n",
      "0.2\n",
      "0.1\n",
      "0.5944779488300023\n",
      "10\n",
      "0.5\n",
      "0.1\n",
      "0.6188388138776549\n",
      "10\n",
      "1\n",
      "0.1\n",
      "0.6533911858489322\n",
      "20\n",
      "0.01\n",
      "0.05\n",
      "0.5751609996065101\n",
      "20\n",
      "0.05\n",
      "0.05\n",
      "0.5738476396599087\n",
      "20\n",
      "0.1\n",
      "0.05\n",
      "0.5732348187383194\n",
      "20\n",
      "0.2\n",
      "0.05\n",
      "0.5613988757020796\n",
      "20\n",
      "0.5\n",
      "0.05\n",
      "0.6159233463283882\n",
      "20\n",
      "1\n",
      "0.05\n",
      "0.6348736288013815\n",
      "30\n",
      "0.01\n",
      "0.03333333333333333\n",
      "0.5223318713542239\n",
      "30\n",
      "0.05\n",
      "0.03333333333333333\n",
      "0.5372625551335076\n",
      "30\n",
      "0.1\n",
      "0.03333333333333333\n",
      "0.5319188701208576\n",
      "30\n",
      "0.2\n",
      "0.03333333333333333\n",
      "0.5387423235417802\n",
      "30\n",
      "0.5\n",
      "0.03333333333333333\n",
      "0.5459476996815646\n",
      "30\n",
      "1\n",
      "0.03333333333333333\n",
      "0.5510036885053755\n"
     ]
    }
   ],
   "source": [
    "# 7\n",
    "\n",
    "topics_range = [5,10,20,30]\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = [.01,.05,.1,.2,.5,1]\n",
    "# alpha.append('symmetric')\n",
    "# alpha.append('asymmetric')\n",
    "\n",
    "# Beta parameter\n",
    "# beta = [1/num_topics]\n",
    "# beta.append('symmetric')\n",
    "# beta.append('auto')\n",
    "\n",
    "model_results = {'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "# iterate through number of topics\n",
    "for num_topics in topics_range:\n",
    "    # iterate through alpha values\n",
    "    for a in alpha:\n",
    "        # iterare through beta values\n",
    "#         for b in beta:\n",
    "        # get the coherence score for the given parameters\n",
    "        cv = compute_coherence_values(corpus=corpus, dictionary=id2word, \n",
    "                                      num_topics=num_topics, a=a, b=1/num_topics)\n",
    "        # Save the model results\n",
    "        model_results['Topics'].append(num_topics)\n",
    "        model_results['Alpha'].append(a)\n",
    "        model_results['Beta'].append(1/num_topics)\n",
    "        model_results['Coherence'].append(cv)\n",
    "        print (num_topics)\n",
    "        print (a)\n",
    "        print (1/num_topics)\n",
    "        print (cv)\n",
    "\n",
    "model_results_7 = pd.DataFrame(model_results)\n",
    "model_results_7.to_csv('tuning/66_lda_tuning_results.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a89b043",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0.01\n",
      "0.2\n",
      "0.6332098218190001\n",
      "5\n",
      "0.05\n",
      "0.2\n",
      "0.6280225817485954\n",
      "5\n",
      "0.1\n",
      "0.2\n",
      "0.6284308781661567\n",
      "5\n",
      "0.2\n",
      "0.2\n",
      "0.6209430848367596\n",
      "5\n",
      "0.5\n",
      "0.2\n",
      "0.6569419559467187\n",
      "5\n",
      "1\n",
      "0.2\n",
      "0.644788659013701\n",
      "10\n",
      "0.01\n",
      "0.1\n",
      "0.5832443382600146\n",
      "10\n",
      "0.05\n",
      "0.1\n",
      "0.5808886033045311\n",
      "10\n",
      "0.1\n",
      "0.1\n",
      "0.5805628030106785\n",
      "10\n",
      "0.2\n",
      "0.1\n",
      "0.5944779488300023\n",
      "10\n",
      "0.5\n",
      "0.1\n",
      "0.6188388138776549\n",
      "10\n",
      "1\n",
      "0.1\n",
      "0.6533911858489322\n",
      "20\n",
      "0.01\n",
      "0.05\n",
      "0.5751609996065101\n",
      "20\n",
      "0.05\n",
      "0.05\n",
      "0.5738476396599087\n",
      "20\n",
      "0.1\n",
      "0.05\n",
      "0.5732348187383194\n",
      "20\n",
      "0.2\n",
      "0.05\n",
      "0.5613988757020796\n",
      "20\n",
      "0.5\n",
      "0.05\n",
      "0.6159233463283882\n",
      "20\n",
      "1\n",
      "0.05\n",
      "0.6348736288013815\n",
      "30\n",
      "0.01\n",
      "0.03333333333333333\n",
      "0.5223318713542239\n",
      "30\n",
      "0.05\n",
      "0.03333333333333333\n",
      "0.5372625551335076\n",
      "30\n",
      "0.1\n",
      "0.03333333333333333\n",
      "0.5319188701208576\n",
      "30\n",
      "0.2\n",
      "0.03333333333333333\n",
      "0.5387423235417802\n",
      "30\n",
      "0.5\n",
      "0.03333333333333333\n",
      "0.5459476996815646\n",
      "30\n",
      "1\n",
      "0.03333333333333333\n",
      "0.5510036885053755\n"
     ]
    }
   ],
   "source": [
    "# 8\n",
    "\n",
    "topics_range = [5,10,20,30]\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = [.01,.05,.1,.2,.5,1]\n",
    "# alpha.append('symmetric')\n",
    "# alpha.append('asymmetric')\n",
    "\n",
    "# Beta parameter\n",
    "# beta = [1/num_topics]\n",
    "# beta.append('symmetric')\n",
    "# beta.append('auto')\n",
    "\n",
    "model_results = {'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "# iterate through number of topics\n",
    "for num_topics in topics_range:\n",
    "    # iterate through alpha values\n",
    "    for a in alpha:\n",
    "        # iterare through beta values\n",
    "#         for b in beta:\n",
    "        # get the coherence score for the given parameters\n",
    "        cv = compute_coherence_values(corpus=corpus, dictionary=id2word, \n",
    "                                      num_topics=num_topics, a=a, b=1/num_topics)\n",
    "        # Save the model results\n",
    "        model_results['Topics'].append(num_topics)\n",
    "        model_results['Alpha'].append(a)\n",
    "        model_results['Beta'].append(1/num_topics)\n",
    "        model_results['Coherence'].append(cv)\n",
    "        print (num_topics)\n",
    "        print (a)\n",
    "        print (1/num_topics)\n",
    "        print (cv)\n",
    "\n",
    "model_results_8 = pd.DataFrame(model_results)\n",
    "model_results_8.to_csv('tuning/77_lda_tuning_results.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "48fd946a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0.01\n",
      "0.2\n",
      "0.6332098218190001\n",
      "5\n",
      "0.05\n",
      "0.2\n",
      "0.6280225817485954\n",
      "5\n",
      "0.1\n",
      "0.2\n",
      "0.6284308781661567\n",
      "5\n",
      "0.2\n",
      "0.2\n",
      "0.6209430848367596\n",
      "5\n",
      "0.5\n",
      "0.2\n",
      "0.6569419559467187\n",
      "5\n",
      "1\n",
      "0.2\n",
      "0.644788659013701\n",
      "10\n",
      "0.01\n",
      "0.1\n",
      "0.5832443382600146\n",
      "10\n",
      "0.05\n",
      "0.1\n",
      "0.5808886033045311\n",
      "10\n",
      "0.1\n",
      "0.1\n",
      "0.5805628030106785\n",
      "10\n",
      "0.2\n",
      "0.1\n",
      "0.5944779488300023\n",
      "10\n",
      "0.5\n",
      "0.1\n",
      "0.6188388138776549\n",
      "10\n",
      "1\n",
      "0.1\n",
      "0.6533911858489322\n",
      "20\n",
      "0.01\n",
      "0.05\n",
      "0.5751609996065101\n",
      "20\n",
      "0.05\n",
      "0.05\n",
      "0.5738476396599087\n",
      "20\n",
      "0.1\n",
      "0.05\n",
      "0.5732348187383194\n",
      "20\n",
      "0.2\n",
      "0.05\n",
      "0.5613988757020796\n",
      "20\n",
      "0.5\n",
      "0.05\n",
      "0.6159233463283882\n",
      "20\n",
      "1\n",
      "0.05\n",
      "0.6348736288013815\n",
      "30\n",
      "0.01\n",
      "0.03333333333333333\n",
      "0.5223318713542239\n",
      "30\n",
      "0.05\n",
      "0.03333333333333333\n",
      "0.5372625551335076\n",
      "30\n",
      "0.1\n",
      "0.03333333333333333\n",
      "0.5319188701208576\n",
      "30\n",
      "0.2\n",
      "0.03333333333333333\n",
      "0.5387423235417802\n",
      "30\n",
      "0.5\n",
      "0.03333333333333333\n",
      "0.5459476996815646\n",
      "30\n",
      "1\n",
      "0.03333333333333333\n",
      "0.5510036885053755\n"
     ]
    }
   ],
   "source": [
    "# 9\n",
    "\n",
    "topics_range = [5,10,20,30]\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = [.01,.05,.1,.2,.5,1]\n",
    "# alpha.append('symmetric')\n",
    "# alpha.append('asymmetric')\n",
    "\n",
    "# Beta parameter\n",
    "# beta = [1/num_topics]\n",
    "# beta.append('symmetric')\n",
    "# beta.append('auto')\n",
    "\n",
    "model_results = {'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "# iterate through number of topics\n",
    "for num_topics in topics_range:\n",
    "    # iterate through alpha values\n",
    "    for a in alpha:\n",
    "        # iterare through beta values\n",
    "#         for b in beta:\n",
    "        # get the coherence score for the given parameters\n",
    "        cv = compute_coherence_values(corpus=corpus, dictionary=id2word, \n",
    "                                      num_topics=num_topics, a=a, b=1/num_topics)\n",
    "        # Save the model results\n",
    "        model_results['Topics'].append(num_topics)\n",
    "        model_results['Alpha'].append(a)\n",
    "        model_results['Beta'].append(1/num_topics)\n",
    "        model_results['Coherence'].append(cv)\n",
    "        print (num_topics)\n",
    "        print (a)\n",
    "        print (1/num_topics)\n",
    "        print (cv)\n",
    "\n",
    "model_results_9 = pd.DataFrame(model_results)\n",
    "model_results_9.to_csv('tuning/88_lda_tuning_results.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2436fe08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0.01\n",
      "0.2\n",
      "0.6332098218190001\n",
      "5\n",
      "0.05\n",
      "0.2\n",
      "0.6280225817485954\n",
      "5\n",
      "0.1\n",
      "0.2\n",
      "0.6284308781661567\n",
      "5\n",
      "0.2\n",
      "0.2\n",
      "0.6209430848367596\n",
      "5\n",
      "0.5\n",
      "0.2\n",
      "0.6569419559467187\n",
      "5\n",
      "1\n",
      "0.2\n",
      "0.644788659013701\n",
      "10\n",
      "0.01\n",
      "0.1\n",
      "0.5832443382600146\n",
      "10\n",
      "0.05\n",
      "0.1\n",
      "0.5808886033045311\n",
      "10\n",
      "0.1\n",
      "0.1\n",
      "0.5805628030106785\n",
      "10\n",
      "0.2\n",
      "0.1\n",
      "0.5944779488300023\n",
      "10\n",
      "0.5\n",
      "0.1\n",
      "0.6188388138776549\n",
      "10\n",
      "1\n",
      "0.1\n",
      "0.6533911858489322\n",
      "20\n",
      "0.01\n",
      "0.05\n",
      "0.5751609996065101\n",
      "20\n",
      "0.05\n",
      "0.05\n",
      "0.5738476396599087\n",
      "20\n",
      "0.1\n",
      "0.05\n",
      "0.5732348187383194\n",
      "20\n",
      "0.2\n",
      "0.05\n",
      "0.5613988757020796\n",
      "20\n",
      "0.5\n",
      "0.05\n",
      "0.6159233463283882\n",
      "20\n",
      "1\n",
      "0.05\n",
      "0.6348736288013815\n",
      "30\n",
      "0.01\n",
      "0.03333333333333333\n",
      "0.5223318713542239\n",
      "30\n",
      "0.05\n",
      "0.03333333333333333\n",
      "0.5372625551335076\n",
      "30\n",
      "0.1\n",
      "0.03333333333333333\n",
      "0.5319188701208576\n",
      "30\n",
      "0.2\n",
      "0.03333333333333333\n",
      "0.5387423235417802\n",
      "30\n",
      "0.5\n",
      "0.03333333333333333\n",
      "0.5459476996815646\n",
      "30\n",
      "1\n",
      "0.03333333333333333\n",
      "0.5510036885053755\n"
     ]
    }
   ],
   "source": [
    "# 10\n",
    "\n",
    "topics_range = [5,10,20,30]\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = [.01,.05,.1,.2,.5,1]\n",
    "# alpha.append('symmetric')\n",
    "# alpha.append('asymmetric')\n",
    "\n",
    "# Beta parameter\n",
    "# beta = [1/num_topics]\n",
    "# beta.append('symmetric')\n",
    "# beta.append('auto')\n",
    "\n",
    "model_results = {'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "# iterate through number of topics\n",
    "for num_topics in topics_range:\n",
    "    # iterate through alpha values\n",
    "    for a in alpha:\n",
    "        # iterare through beta values\n",
    "#         for b in beta:\n",
    "        # get the coherence score for the given parameters\n",
    "        cv = compute_coherence_values(corpus=corpus, dictionary=id2word, \n",
    "                                      num_topics=num_topics, a=a, b=1/num_topics)\n",
    "        # Save the model results\n",
    "        model_results['Topics'].append(num_topics)\n",
    "        model_results['Alpha'].append(a)\n",
    "        model_results['Beta'].append(1/num_topics)\n",
    "        model_results['Coherence'].append(cv)\n",
    "        print (num_topics)\n",
    "        print (a)\n",
    "        print (1/num_topics)\n",
    "        print (cv)\n",
    "\n",
    "model_results_10 = pd.DataFrame(model_results)\n",
    "model_results_10.to_csv('tuning/99_lda_tuning_results.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7333034a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = pd.concat([model_results_1, model_results_2, model_results_3, model_results_4, model_results_5,\n",
    "                          model_results_6, model_results_7, model_results_8, model_results_9, model_results_10])\n",
    "model_results.to_csv(\"tuning/model_results.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd7bf03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = model_results.groupby(['Topics', 'Alpha'], as_index=False).mean()\n",
    "model_results = model_results.sort_values(by='Coherence', ascending=False)\n",
    "model_results.to_csv('2_lda_tuning_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2d009d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topics</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Beta</th>\n",
       "      <th>Coherence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.656942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.653391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.644789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.634874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.633210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.628431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.628023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.620943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.618839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.615923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.594478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.583244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.580889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.580563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.575161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.573848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.573235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.561399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.551004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.545948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.538742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>30</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.537263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.531919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>30</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.522332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topics  Alpha      Beta  Coherence\n",
       "4        5   0.50  0.200000   0.656942\n",
       "11      10   1.00  0.100000   0.653391\n",
       "5        5   1.00  0.200000   0.644789\n",
       "17      20   1.00  0.050000   0.634874\n",
       "0        5   0.01  0.200000   0.633210\n",
       "2        5   0.10  0.200000   0.628431\n",
       "1        5   0.05  0.200000   0.628023\n",
       "3        5   0.20  0.200000   0.620943\n",
       "10      10   0.50  0.100000   0.618839\n",
       "16      20   0.50  0.050000   0.615923\n",
       "9       10   0.20  0.100000   0.594478\n",
       "6       10   0.01  0.100000   0.583244\n",
       "7       10   0.05  0.100000   0.580889\n",
       "8       10   0.10  0.100000   0.580563\n",
       "12      20   0.01  0.050000   0.575161\n",
       "13      20   0.05  0.050000   0.573848\n",
       "14      20   0.10  0.050000   0.573235\n",
       "15      20   0.20  0.050000   0.561399\n",
       "23      30   1.00  0.033333   0.551004\n",
       "22      30   0.50  0.033333   0.545948\n",
       "21      30   0.20  0.033333   0.538742\n",
       "19      30   0.05  0.033333   0.537263\n",
       "20      30   0.10  0.033333   0.531919\n",
       "18      30   0.01  0.033333   0.522332"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7bc707ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# priors = pd.pivot_table(model_results,index=[\"Topics\"],columns=[\"Alpha\"],values=['Coherence'])\n",
    "# priors.columns = range(priors.shape[1])\n",
    "# priors.columns = ['.01','.05','.1','.2','.5','1']\n",
    "# df.head(1)\n",
    "# priors = priors.reset_index()\n",
    "# priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18db60ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# priors.to_csv(\"siri_lda_tuning_results.csv\",index=True, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "735bdb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "  \n",
    "# # dummy data\n",
    "# x1 = priors['Topics']\n",
    "# A = priors['.01']\n",
    "# B = priors['.05']\n",
    "# C = priors['.1']\n",
    "# D = priors['.2']\n",
    "# E = priors['.5']\n",
    "# F = priors['1']\n",
    "\n",
    "# # creates two subplots\n",
    "# # fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (24, 12))\n",
    "\n",
    "# fig, ax = plt.subplots(2, 3, figsize = (24,12))\n",
    "\n",
    "# # Plot without grid\n",
    "# ax[0,0].plot(x1, A, label='0.01', color='tab:blue')\n",
    "# ax[0,1].plot(x1, B, label='0.05', color='tab:orange')\n",
    "# ax[0,2].plot(x1, C, label='0.1', color='tab:green')\n",
    "# ax[1,0].plot(x1, D, label='0.2', color='tab:red')\n",
    "# ax[1,1].plot(x1, E, label='0.5', color='tab:purple')\n",
    "# ax[1,2].plot(x1, F, label='1', color='tab:brown')\n",
    "\n",
    "# ax[0,0].set_xlim(xmin=9)\n",
    "# ax[0,0].set_title('siri, α=.01, Beta=1/K')\n",
    "# ax[0,0].set_xlabel('K')\n",
    "# ax[0,0].set_ylabel('Cv')\n",
    "\n",
    "# ax[0,1].set_xlim(xmin=9)\n",
    "# ax[0,1].set_title('siri, α=.05, Beta=1/K')\n",
    "# ax[0,1].set_xlabel('K')\n",
    "# ax[0,1].set_ylabel('Cv')\n",
    "\n",
    "# ax[0,2].set_xlim(xmin=9)\n",
    "# ax[0,2].set_title('siri, α=.1, Beta=1/K')\n",
    "# ax[0,2].set_xlabel('K')\n",
    "# ax[0,2].set_ylabel('Cv')\n",
    "\n",
    "# ax[1,0].set_xlim(xmin=9)\n",
    "# ax[1,0].set_title('siri, α=.2, Beta=1/K')\n",
    "# ax[1,0].set_xlabel('K')\n",
    "# ax[1,0].set_ylabel('Cv')\n",
    "\n",
    "# ax[1,1].set_xlim(xmin=9)\n",
    "# ax[1,1].set_title('siri, α=.5, Beta=1/K')\n",
    "# ax[1,1].set_xlabel('K')\n",
    "# ax[1,1].set_ylabel('Cv')\n",
    "\n",
    "# ax[1,2].set_xlim(xmin=9)\n",
    "# ax[1,2].set_title('siri, α=1, Beta=1/K')\n",
    "# ax[1,2].set_xlabel('K')\n",
    "# ax[1,2].set_ylabel('Cv')\n",
    "\n",
    "# # fig.tight_layout()\n",
    "# fig.set_facecolor(\"w\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7b87ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
